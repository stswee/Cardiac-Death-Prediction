{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3b6e80-e53a-4f4c-837a-df48d4a7f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPUs\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5,6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d01b8c-60a6-4fb1-bdc1-a4689b75dbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Prompts</th>\n",
       "      <th>labels</th>\n",
       "      <th>Prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P0001</td>\n",
       "      <td>Age: 58\\nGender: Male \\nWeight: 83 kg\\nHeight:...</td>\n",
       "      <td>0</td>\n",
       "      <td>RANKING: 1. Survivor\\nREASONING: \\n\\nBased on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>P0002</td>\n",
       "      <td>Age: 58\\nGender: Male \\nWeight: 74 kg\\nHeight:...</td>\n",
       "      <td>0</td>\n",
       "      <td>RANKING: \\n1. Survivor\\nREASONING: \\nThe patie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>P0003</td>\n",
       "      <td>Age: 69\\nGender: Male \\nWeight: 83 kg\\nHeight:...</td>\n",
       "      <td>0</td>\n",
       "      <td>RANKING: \\n1. Survivor\\nREASONING: \\nBased on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>P0004</td>\n",
       "      <td>Age: 56\\nGender: Female \\nWeight: 84 kg\\nHeigh...</td>\n",
       "      <td>0</td>\n",
       "      <td>RANKING: 1. Survivor \\nREASONING: \\n\\nBased on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>P0005</td>\n",
       "      <td>Age: 70\\nGender: Male \\nWeight: 97 kg\\nHeight:...</td>\n",
       "      <td>0</td>\n",
       "      <td>RANKING: 1. Survivor\\nREASONING: \\nThe patient...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0 Patient ID  \\\n",
       "0             0           0      P0001   \n",
       "1             1           1      P0002   \n",
       "2             2           2      P0003   \n",
       "3             3           3      P0004   \n",
       "4             4           4      P0005   \n",
       "\n",
       "                                             Prompts  labels  \\\n",
       "0  Age: 58\\nGender: Male \\nWeight: 83 kg\\nHeight:...       0   \n",
       "1  Age: 58\\nGender: Male \\nWeight: 74 kg\\nHeight:...       0   \n",
       "2  Age: 69\\nGender: Male \\nWeight: 83 kg\\nHeight:...       0   \n",
       "3  Age: 56\\nGender: Female \\nWeight: 84 kg\\nHeigh...       0   \n",
       "4  Age: 70\\nGender: Male \\nWeight: 97 kg\\nHeight:...       0   \n",
       "\n",
       "                                           Prognosis  \n",
       "0  RANKING: 1. Survivor\\nREASONING: \\n\\nBased on ...  \n",
       "1  RANKING: \\n1. Survivor\\nREASONING: \\nThe patie...  \n",
       "2  RANKING: \\n1. Survivor\\nREASONING: \\nBased on ...  \n",
       "3  RANKING: 1. Survivor \\nREASONING: \\n\\nBased on...  \n",
       "4  RANKING: 1. Survivor\\nREASONING: \\nThe patient...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading\n",
    "\n",
    "# Import packages\n",
    "import pandas as pd\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv(\"../Data/subject-info-cleaned-with-prognosis-D-Llama3B.csv\")\n",
    "\n",
    "# Get prognosis and outcome\n",
    "# df = df[['Prognosis', 'Outcome']]\n",
    "\n",
    "# Map labels to integers\n",
    "# Survivor = 0, SCD = 1, PFD = 2\n",
    "label_map = {\"survivor\": 0, \"sudden cardiac death\": 1, \"pump failure death\": 2}\n",
    "df['Outcome'] = df['Outcome'].map(label_map)\n",
    "df.rename(columns = {\"Outcome\": \"labels\"}, inplace = True)\n",
    "df.head()\n",
    "\n",
    "# Shuffle dataset\n",
    "# df = df.sample(frac = 1, random_state = 42)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b95735b-4389-4bb2-97ce-b27f56619cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 58\n",
      "Gender: Male \n",
      "Weight: 83 kg\n",
      "Height: 163 cm\n",
      "NYHA Class: III\n",
      "Blood Pressure: 110/75 mmHg\n",
      "Past Medical History: Idiopathic dilated cardiomyopathy\n",
      "Albumin (g/L): 42,4\n",
      "ALT or GPT (IU/L): 10.0\n",
      "AST or GOT (IU/L): 20.0\n",
      "Total Cholesterol (mmol/L): 5,4\n",
      "Creatinine (mmol/L): 106.0\n",
      "Gamma-glutamil transpeptidase (IU/L): 20\n",
      "Glucose (mmol/L): 5,7\n",
      "Hemoglobin (g/L): 132.0\n",
      "HDL (mmol/L): 1,29\n",
      "Potassium (mEq/L): 4,6\n",
      "LDL (mmol/L): 3,36\n",
      "Sodium (mEq/L): 141.0\n",
      "Pro-BNP (ng/L): 1834.0\n",
      "Protein (g/L): 69\n",
      "T3 (pg/dL): 0,05\n",
      "T4 (ng/L): 15\n",
      "Troponin (ng/mL): 0,01\n",
      "TSH (mIU/L): 3,02\n",
      "Urea (mg/dL): 7,12\n",
      "LVEF (%): 35.0\n",
      "Medications: Beta Blockers, Digoxin, Loop Diuretics, ACE Inhibitor\n",
      "ECG Impression:\n",
      "        - Ventricular Extrasystole: Polymorphic\n",
      "        - Ventricular Tachycardia: Non-sustained VT\n",
      "        - Non-sustained ventricular tachycardia (CH>10): Yes\n",
      "        - Paroxysmal supraventricular tachyarrhythmia: Unknown paroxysmal supraventricular tachyarrhythmia code\n",
      "        - Bradycardia: Unknown bradycardia code\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(df['Prompts'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8a3c57-95cd-49e1-97e3-d11ec10f0763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANKING: 1. Survivor\n",
      "REASONING: \n",
      "\n",
      "Based on the provided patient data, the patient's prognosis is most likely to be a survivor. The patient has a history of idiopathic dilated cardiomyopathy, which is a condition where the heart muscle becomes weakened and the heart chambers become enlarged. This condition can lead to heart failure, arrhythmias, and decreased cardiac function.\n",
      "\n",
      "The patient's current NYHA Class III indicates that they have severe symptoms, such as shortness of breath, fatigue, and swelling in the legs, ankles, and feet. However, despite these symptoms, the patient's hemoglobin level (132 g/L) and serum potassium level (4.6 mEq/L) are within normal limits.\n",
      "\n",
      "The patient's LVEF (left ventricular ejection fraction) is 35%, which is significantly below the normal range (50-70%). However, the patient is already on beta blockers, digoxin, and loop diuretics, which are standard treatments for heart failure. The patient's creatinine level (106.0 mmol/L) is elevated, indicating impaired kidney function, but this is not uncommon in patients with heart failure.\n",
      "\n",
      "The ECG findings of ventricular extrasystoles, non-sustained ventricular tachycardia, and non-sustained ventricular tachycardia are concerning for arrhythmias, which can be life-threatening. However, the patient is already on medications that can help manage these arrhythmias.\n",
      "\n",
      "Given the patient's current medications, the presence of heart failure symptoms, and the ECG findings, the patient's prognosis is still relatively favorable. With proper management and monitoring, the patient is likely to survive for the next few years.\n",
      "\n",
      "RANKING: 2. Sudden cardiac death\n",
      "REASONING: \n",
      "\n",
      "Although the patient's prognosis is not as favorable as the survivor ranking, sudden cardiac death is still a possible outcome. The patient's LVEF is significantly below normal, and the patient has a history of arrhythmias, which can increase the risk of sudden cardiac death.\n",
      "\n",
      "However, the patient is already on beta blockers, digoxin, and loop diuretics, which can help manage heart failure and arrhythmias. The patient's hemoglobin level and serum potassium level are within normal limits, which reduces the risk of sudden cardiac death.\n",
      "\n",
      "RANKING: 3. Pump failure death\n",
      "REASONING: \n",
      "\n",
      "Pump failure death is the least likely outcome, given the patient's current treatment regimen and the presence of heart failure symptoms. The patient is already on beta blockers, digoxin, and loop diuretics, which can help manage heart failure.\n",
      "\n",
      "However, the patient's LVEF is significantly below normal, and the patient has a history of arrhythmias, which can increase the risk of pump failure. Additionally, the patient's creatinine level is elevated, indicating impaired kidney function, which can increase the risk of pump failure.\n",
      "\n",
      "Overall, while pump failure death is a possible outcome, it is the least likely given the patient's current treatment regimen and the presence of heart failure symptoms.\n"
     ]
    }
   ],
   "source": [
    "print(df['Prognosis'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae4da5e5-8eda-49fe-849f-fe8e82a2c108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sswee/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in BioBERT with classification head\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch import cuda\n",
    "\n",
    "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "num_labels = 3  # Three possible outcomes\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a65164ec-f466-4290-b0d5-5e57f46b006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Data split (for testing)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size = 0.3, random_state = 42, stratify = df['labels'])\n",
    "\n",
    "# Get encodings\n",
    "train_encodings = tokenizer(list(train_df['Prognosis']), truncation = True, padding = True)\n",
    "test_encodings = tokenizer(list(test_df['Prognosis']), truncation = True, padding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d0eee36-8788-40a0-b15a-58a6e3a63c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "dataset = Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08ac4529-9fc0-4360-bc59-ce82385216f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [00:00<00:00, 1671.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load BioBERT tokenizer\n",
    "# model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "num_labels = 3  # Three possible outcomes\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Prognosis\"], padding=\"max_length\", truncation=True, max_length = 512)\n",
    "\n",
    "# Apply tokenization\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a293c0b1-3d7f-4af2-b9bb-5a63047a5ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_test = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test[\"train\"]\n",
    "val_dataset = train_test[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f00b7f2d-a0c5-4c16-b5a0-f63e4e6d195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)  # Convert logits to class predictions\n",
    "\n",
    "    # Compute accuracy\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "\n",
    "    # Compute precision, recall, f1-score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    # Compute AUC (only if there are at least 2 classes)\n",
    "    # auc = roc_auc_score(labels, logits, multi_class=\"ovr\") if len(set(labels)) > 1 else 0\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "        #\"auc\": auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2c793d1-212d-4e51-8c99-22ae1bbc8d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sswee/myenv/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../Results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"../logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a921c24e-09e4-4631-81f8-349b4e916903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4061917/360158454.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/home/sswee/myenv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [129/129 01:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.485500</td>\n",
       "      <td>0.391664</td>\n",
       "      <td>0.888235</td>\n",
       "      <td>0.896955</td>\n",
       "      <td>0.888235</td>\n",
       "      <td>0.872773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>0.379228</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.760660</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.800151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.343995</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.904046</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.898669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sswee/myenv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/sswee/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/sswee/myenv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/sswee/myenv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=129, training_loss=0.41489963198817054, metrics={'train_runtime': 81.5779, 'train_samples_per_second': 24.97, 'train_steps_per_second': 1.581, 'total_flos': 535962031911936.0, 'train_loss': 0.41489963198817054, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b747f67c-9573-4a25-bb44-544348a7def4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sswee/myenv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.34399500489234924,\n",
       " 'eval_accuracy': 0.9058823529411765,\n",
       " 'eval_precision': 0.9040459467369037,\n",
       " 'eval_recall': 0.9058823529411765,\n",
       " 'eval_f1': 0.8986689270302716,\n",
       " 'eval_runtime': 0.9122,\n",
       " 'eval_samples_per_second': 186.362,\n",
       " 'eval_steps_per_second': 12.059,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
